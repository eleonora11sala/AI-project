{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from loadData import loadData\n",
    "from extract_fiducials import extract_fiducials\n",
    "from extract_features import extract_features\n",
    "from preprocess import preprocess\n",
    "from artifacts import artifacts\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e19c1e0d0155dcd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_PATH = 'C:/Users/user/Desktop/AI-project/train'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "702e92f8512dbb49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ppgs_128, speaks_128, annotations_128, ppgs_250, speaks_250, annotations_250 = loadData(ROOT_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "686c80a6af55cde4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4d8388648f76d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(ppgs_128)):\n",
    "    ppgs_128[i] = preprocess(ppgs_128[i],128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14b6987c0aa0af11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(ppgs_250)):\n",
    "    ppgs_250[i] = preprocess(ppgs_250[i],250)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbd071497f66d462"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_title(\"Patient 001_128\")\n",
    "fs=128\n",
    "t = np.arange(0, ppgs_128[0].shape[0]/fs, 1/fs)\n",
    "axs.plot(t[0:200*128], ppgs_128[0][0:200*128], color='C0')\n",
    "axs.plot((speaks_128[0][0:300])/128, ppgs_128[0][speaks_128[0][0:300]],'*', color='r')\n",
    "axs.set_xlabel(\"Time [s]\")\n",
    "axs.set_ylabel(\"Amplitude\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6793fee990ec8a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artifacts removal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2995227fd247865c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_speaks_128=list()\n",
    "n_annotations_128=list()\n",
    "\n",
    "for i in range(len(speaks_128)):\n",
    "    speaks, annotations = artifacts(speaks_128[i],ppgs_128[i],annotations_128[i])\n",
    "    n_speaks_128.append(speaks)\n",
    "    n_annotations_128.append(annotations)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1818bde511f1f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_title(\"Patient 001_128\")\n",
    "fs=128\n",
    "t = np.arange(0, ppgs_128[0].shape[0]/fs, 1/fs)\n",
    "axs.plot(t[0:200*128], ppgs_128[0][0:200*128], color='C0')\n",
    "axs.plot((n_speaks_128[0][0:200])/128, ppgs_128[0][n_speaks_128[0][0:200]],'*', color='r')\n",
    "axs.set_xlabel(\"Time [s]\")\n",
    "axs.set_ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd6aea8bb619e50d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_speaks_250=list()\n",
    "n_annotations_250=list()\n",
    "\n",
    "for i in range(len(speaks_250)):\n",
    "    speaks, annotations = artifacts(speaks_250[i],ppgs_250[i],annotations_250[i])\n",
    "    n_speaks_250.append(speaks)\n",
    "    n_annotations_250.append(annotations)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eba965be421474e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_speaks_128[1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c63dea5b676693"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract fiducials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d935a0b4727ff2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fiducials_128 = list()\n",
    "\n",
    "for i in range(len(ppgs_128)):\n",
    "   fiducials_128.append(extract_fiducials(ppgs_128[i], n_speaks_128[i],128))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9a2280f910f2b75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fiducials_250 = list()\n",
    "\n",
    "for i in range(len(ppgs_250)):\n",
    "   fiducials_250.append(extract_fiducials(ppgs_250[i], n_speaks_250[i],250))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7ec76e34775277e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write fiducials to CSV\n",
    "Because the process of extracting fiducials is time consuming, we write them on files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2c2b986b5070ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "for fiducial in fiducials_128:\n",
    "    file_name = f\"C:/Users/user/Desktop/AI-project/fiducials/128/fiducial_{i}_128.csv\"\n",
    "    fiducial.to_csv(file_name, sep=',', index=False, encoding='utf-8')\n",
    "    i = i + 1\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92013d314fcfdfa1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "for fiducial in fiducials_250:\n",
    "    file_name = f\"C:/Users/user/Desktop/AI-project/fiducials/250/fiducial_{i}_250.csv\"\n",
    "    fiducial.to_csv(file_name, sep=',', index=False, encoding='utf-8')\n",
    "    i = i + 1\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec6a2d110285dcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26bf8e027db0d14"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "folder_path = u'C:/Users/user/Desktop/AI-project/fiducials/128' \n",
    "\n",
    "# List all files in the folder\n",
    "file_names = [file for file in os.listdir(folder_path) if file.endswith('_128.csv')]\n",
    "\n",
    "fiducials_128_copy = []\n",
    "\n",
    "i = 0\n",
    "# Loop through each file and concatenate the data\n",
    "for i in range(len(file_names)):\n",
    "    file_path = f\"C:/Users/user/Desktop/AI-project/fiducials/128/fiducial_{i}_128.csv\"\n",
    "    fiducial = pd.read_csv(file_path)\n",
    "    fiducials_128_copy.append(fiducial)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:13:28.165480800Z",
     "start_time": "2023-12-20T13:13:27.885921200Z"
    }
   },
   "id": "640fc82cbb11c215"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "range(0, 62)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_path = u'C:/Users/user/Desktop/AI-project/fiducials/250' \n",
    "\n",
    "# List all files in the folder\n",
    "file_names = [file for file in os.listdir(folder_path) if file.endswith('_250.csv')]\n",
    "\n",
    "fiducials_250_copy = []\n",
    "\n",
    "i = 0\n",
    "# Loop through each file and concatenate the data\n",
    "for i in range(len(file_names)):\n",
    "    file_path = f\"C:/Users/user/Desktop/AI-project/fiducials/128/fiducial_{i}_250.csv\"\n",
    "    fiducial = pd.read_csv(file_path)\n",
    "    fiducials_250_copy.append(fiducial)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:12:04.924389900Z",
     "start_time": "2023-12-20T13:12:04.878351400Z"
    }
   },
   "id": "7d16c0b4b8babb71"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m features_128 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(fiducials_128_copy)):\n\u001B[0;32m      4\u001B[0m     features_128\u001B[38;5;241m.\u001B[39mappend(extract_features(fiducials_128_copy[i], ppgs_128[i], \u001B[38;5;241m128\u001B[39m))\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "features_128 = []\n",
    "\n",
    "for i in range(len(fiducials_128_copy)):\n",
    "    features_128.append(extract_features(fiducials_128_copy[i], ppgs_128[i], 128))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:17:21.226966100Z",
     "start_time": "2023-12-20T13:17:21.181082300Z"
    }
   },
   "id": "7dce4b8e07a5bbfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_250 = []\n",
    "\n",
    "for i in range(len(fiducials_250_copy)):\n",
    "    features_250.append(extract_features(fiducials_250_copy[i], ppgs_250[i], 250))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac69bb3c18ed1cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add annotation to peaks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478ac193d34453e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_128)):\n",
    "    features_128[i]['annotation'] = n_annotations_128[i]\n",
    "for i in range(len(features_250)):\n",
    "    features_250[i]['annotation'] = n_annotations_250[i]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3da0c2dd1c0244b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove rows with null values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803da4d15c18ea3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_128)):\n",
    "    # Find rows with at least one NaN value using np.isnan()\n",
    "    rows_with_nan = features_128[i][features_128[i].applymap(lambda x: np.isnan(x) if isinstance(x, (float, np.float64)) else False).any(axis=1)]\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    features_128[i] = features_128[i].drop(rows_with_nan.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ece17e9a4968e551"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_250)):\n",
    "    # Find rows with at least one NaN value using np.isnan()\n",
    "    rows_with_nan = features_250[i][features_250[i].applymap(lambda x: np.isnan(x) if isinstance(x, (float, np.float64)) else False).any(axis=1)]\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    features_250[i] = features_250[i].drop(rows_with_nan.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6e44234a1b2883"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove rows with TP = 0 --> ST = inf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b95fdd5186ae75a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_128)):\n",
    "    features_128[i] = features_128[i][features_128[i]['TP'] != 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1baff2ccd5e777"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_250)):\n",
    "    features_250[i] = features_250[i][features_250[i]['TP'] != 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3239c5106f7258f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46763b62edf4618"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in range(len(features_128)):\n",
    "    \n",
    "   normalized_df = features_128[i].iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "   features_128[i] = pd.concat([normalized_df, features_128[i].iloc[:, -1]], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "312f1795c4dd182e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_250)):\n",
    "   normalized_df = features_250[i].iloc[:, :-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "   features_250[i] = pd.concat([normalized_df, features_250[i].iloc[:, -1]], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67a30abccebd879"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Delete eventual NaN caused by Normalization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e1fe70fca420cf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_128)):\n",
    "    # Find rows with at least one NaN value using np.isnan()\n",
    "    rows_with_nan = features_128[i][features_128[i].applymap(lambda x: np.isnan(x) if isinstance(x, (float, np.float64)) else False).any(axis=1)]\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    features_128[i] = features_128[i].drop(rows_with_nan.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e94b88eabf2b2fe3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(features_250)):\n",
    "    # Find rows with at least one NaN value using np.isnan()\n",
    "    rows_with_nan = features_250[i][features_250[i].applymap(lambda x: np.isnan(x) if isinstance(x, (float, np.float64)) else False).any(axis=1)]\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    features_250[i] = features_250[i].drop(rows_with_nan.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd0e6d7e3e38538"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(features_128)):\n",
    "    features_128[i] = features_128[i][features_128[i]['TP'] != 0]\n",
    "for i in range(len(features_250)):\n",
    "    features_250[i] = features_250[i][features_250[i]['TP'] != 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "978e2c4518bf1f29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_250[1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17cfee30c96dbec7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write features to csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ce4b53c1c4f1af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "for feature in features_128:\n",
    "    file_name = f\"C:/Users/cricr/PycharmProjects/AI-project/features/128/features_{i}_128.csv\"\n",
    "    feature.to_csv(file_name, sep=',', index=False, encoding='utf-8')\n",
    "    i = i + 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "978b21c6cc8f230a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "for feature in features_250:\n",
    "    file_name = f\"C:/Users/cricr/PycharmProjects/AI-project/features/250/features_{i}_250.csv\"\n",
    "    feature.to_csv(file_name, sep=',', index=False, encoding='utf-8')\n",
    "    i = i + 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b96c658b223000e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
